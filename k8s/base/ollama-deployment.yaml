apiVersion: apps/v1
kind: Deployment
metadata:
  name: ollama
  namespace: microservices-demo
  labels:
    app.kubernetes.io/name: microservices-demo
    app.kubernetes.io/component: ollama
    app.kubernetes.io/version: "1.0.0"
spec:
  replicas: 1  # Single instance due to model size and resource requirements
  strategy:
    type: Recreate  # Model data requires consistent storage
  selector:
    matchLabels:
      app.kubernetes.io/name: microservices-demo
      app.kubernetes.io/component: ollama
  template:
    metadata:
      labels:
        app.kubernetes.io/name: microservices-demo
        app.kubernetes.io/component: ollama
        app.kubernetes.io/version: "1.0.0"
      annotations:
        prometheus.io/scrape: "false"
    spec:
      initContainers:
        - name: model-downloader
          image: ollama/ollama:latest
          command: ["/bin/sh", "-c"]
          args:
            - |
              echo "Waiting for Ollama server to be ready..."
              sleep 10
              echo "Downloading llama3.2 model..."
              ollama pull llama3.2
              echo "Model download complete!"
          env:
            - name: OLLAMA_HOST
              value: "http://localhost:11434"
          volumeMounts:
            - name: ollama-data
              mountPath: /root/.ollama
          resources:
            requests:
              memory: "1Gi"
              cpu: "500m"
            limits:
              memory: "2Gi"
              cpu: "1000m"
      containers:
        - name: ollama
          image: ollama/ollama:latest
          ports:
            - name: http
              containerPort: 11434
              protocol: TCP
          env:
            - name: OLLAMA_ORIGINS
              value: "*"
            - name: OLLAMA_HOST
              value: "0.0.0.0:11434"
          volumeMounts:
            - name: ollama-data
              mountPath: /root/.ollama
          livenessProbe:
            httpGet:
              path: /api/tags
              port: http
            initialDelaySeconds: 120  # Allow time for model loading
            periodSeconds: 30
            timeoutSeconds: 10
            failureThreshold: 3
          readinessProbe:
            exec:
              command:
                - /bin/sh
                - -c
                - "ollama list | grep -q llama3.2"
            initialDelaySeconds: 180  # Allow time for model download and loading
            periodSeconds: 10
            timeoutSeconds: 10
            failureThreshold: 5
          resources:
            requests:
              memory: "4Gi"   # Minimum for llama3.2 model
              cpu: "1000m"
            limits:
              memory: "8Gi"   # Allow headroom for model inference
              cpu: "4000m"
          securityContext:
            allowPrivilegeEscalation: false
            runAsNonRoot: true
            runAsUser: 1000
            capabilities:
              drop:
                - ALL
      volumes:
        - name: ollama-data
          persistentVolumeClaim:
            claimName: ollama-data-pvc
      securityContext:
        fsGroup: 1000
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: ollama-data-pvc
  namespace: microservices-demo
  labels:
    app.kubernetes.io/name: microservices-demo
    app.kubernetes.io/component: ollama
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 10Gi  # 2GB for model + overhead
  storageClassName: standard  # Adjust based on your cluster's storage classes
